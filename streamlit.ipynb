{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VrDmbjYEOM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066ca957-4222-4e51-d3ab-c68a5a633898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.9/309.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.1/136.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit transformers einops accelerate langchain bitsandbytes pypdf sentence_transformers llama_index llama-index-llms-huggingface llama-index-embeddings-langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "Vg67ceQI846g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "XENw7dWS8_7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "orBE1thRChQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f1zCnnOExpv",
        "outputId": "22cf6842-5016-45c4-f213-8e9be352b200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) no\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n",
        "! streamlit run streamlit_llamaindex_final.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "wBlikOQcBYZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a522ae2-47da-4227-c34b-c24cfa8e84b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "104.197.0.98\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.197.0.98:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.612s\n",
            "your url is: https://puny-needles-film.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n",
        "! streamlit run streamlit_llamaindex_final.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1kSmCt38gqB",
        "outputId": "1b77a9f9-46ba-44a9-de53-de8dfe1bf960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.135.117.225\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.135.117.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.098s\n",
            "your url is: https://huge-showers-hammer.loca.lt\n",
            "config.json: 100% 632/632 [00:00<00:00, 3.05MB/s]\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 31.8MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 10.5M/9.98G [00:00<01:56, 85.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 31.5M/9.98G [00:00<01:13, 135MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 62.9M/9.98G [00:00<00:57, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 94.4M/9.98G [00:00<00:52, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 126M/9.98G [00:00<00:49, 197MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 147M/9.98G [00:00<00:49, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 168M/9.98G [00:00<00:49, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 189M/9.98G [00:01<00:49, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 210M/9.98G [00:01<00:49, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 231M/9.98G [00:01<00:49, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 252M/9.98G [00:01<00:49, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 273M/9.98G [00:01<00:49, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 294M/9.98G [00:02<02:43, 59.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 315M/9.98G [00:02<02:10, 74.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 336M/9.98G [00:02<01:51, 86.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 357M/9.98G [00:02<01:39, 96.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 377M/9.98G [00:02<01:30, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 398M/9.98G [00:03<01:23, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 419M/9.98G [00:03<01:27, 110MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 440M/9.98G [00:03<01:28, 108MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 461M/9.98G [00:03<01:30, 106MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 482M/9.98G [00:03<01:22, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 503M/9.98G [00:03<01:14, 127MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 524M/9.98G [00:04<01:07, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 545M/9.98G [00:04<01:03, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 566M/9.98G [00:04<01:00, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 587M/9.98G [00:04<00:57, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 608M/9.98G [00:04<00:54, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 640M/9.98G [00:04<00:50, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 671M/9.98G [00:04<00:47, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 692M/9.98G [00:04<00:47, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 713M/9.98G [00:05<00:50, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 734M/9.98G [00:05<00:49, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 755M/9.98G [00:05<00:50, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 786M/9.98G [00:05<00:47, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 807M/9.98G [00:05<00:47, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 839M/9.98G [00:05<00:46, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 860M/9.98G [00:05<00:48, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 881M/9.98G [00:05<00:48, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 902M/9.98G [00:06<00:49, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 923M/9.98G [00:06<00:49, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 944M/9.98G [00:06<00:49, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 965M/9.98G [00:06<00:47, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 986M/9.98G [00:07<02:30, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.01G/9.98G [00:07<01:58, 75.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.04G/9.98G [00:07<01:34, 94.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.98G [00:07<01:31, 98.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.08G/9.98G [00:07<01:19, 112MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.11G/9.98G [00:08<01:05, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.13G/9.98G [00:08<01:00, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.15G/9.98G [00:08<00:56, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.17G/9.98G [00:08<00:56, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.20G/9.98G [00:08<00:53, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.23G/9.98G [00:08<00:48, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.26G/9.98G [00:08<00:45, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.28G/9.98G [00:09<00:48, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.30G/9.98G [00:09<00:48, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.32G/9.98G [00:09<00:51, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.34G/9.98G [00:09<00:49, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.36G/9.98G [00:09<00:48, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.38G/9.98G [00:09<00:48, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.41G/9.98G [00:09<00:56, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.43G/9.98G [00:10<01:43, 82.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.45G/9.98G [00:10<01:34, 90.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.47G/9.98G [00:10<01:20, 105MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.49G/9.98G [00:10<01:08, 123MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.51G/9.98G [00:11<01:39, 85.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.53G/9.98G [00:11<01:28, 94.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.55G/9.98G [00:11<01:18, 107MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.57G/9.98G [00:11<01:18, 107MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.59G/9.98G [00:11<01:12, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.61G/9.98G [00:12<01:32, 90.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.64G/9.98G [00:12<01:19, 105MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.66G/9.98G [00:12<01:09, 120MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.68G/9.98G [00:12<01:10, 118MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.70G/9.98G [00:12<01:23, 99.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.72G/9.98G [00:13<01:20, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.74G/9.98G [00:13<01:08, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.76G/9.98G [00:13<01:21, 101MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.78G/9.98G [00:13<01:11, 114MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.80G/9.98G [00:13<01:27, 93.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.82G/9.98G [00:14<01:14, 110MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.85G/9.98G [00:14<01:04, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [00:14<00:57, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.89G/9.98G [00:14<00:55, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.91G/9.98G [00:15<02:42, 49.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [00:15<02:09, 62.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.95G/9.98G [00:15<01:46, 75.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.97G/9.98G [00:15<01:26, 92.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.99G/9.98G [00:15<01:13, 108MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.01G/9.98G [00:16<01:04, 123MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.03G/9.98G [00:16<00:58, 137MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.06G/9.98G [00:16<00:53, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.08G/9.98G [00:16<00:49, 160MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.10G/9.98G [00:16<00:48, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.12G/9.98G [00:16<00:49, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.14G/9.98G [00:16<00:46, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [00:16<00:45, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.18G/9.98G [00:16<00:42, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.21G/9.98G [00:17<00:40, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.23G/9.98G [00:17<00:39, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.25G/9.98G [00:17<00:41, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.28G/9.98G [00:17<00:41, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.30G/9.98G [00:17<00:41, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.32G/9.98G [00:17<00:40, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.34G/9.98G [00:17<00:40, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.36G/9.98G [00:20<05:08, 24.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.38G/9.98G [00:20<03:47, 33.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.40G/9.98G [00:20<02:50, 44.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.42G/9.98G [00:20<02:18, 54.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.44G/9.98G [00:20<01:51, 67.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.46G/9.98G [00:21<01:29, 84.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.50G/9.98G [00:21<01:08, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.52G/9.98G [00:21<01:04, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.54G/9.98G [00:21<00:58, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.98G [00:21<00:52, 142MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.58G/9.98G [00:21<00:47, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.61G/9.98G [00:21<00:42, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.64G/9.98G [00:21<00:39, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.66G/9.98G [00:22<00:38, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.98G [00:22<00:38, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.71G/9.98G [00:22<00:39, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.73G/9.98G [00:22<00:39, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [00:22<00:39, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.77G/9.98G [00:22<00:39, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.79G/9.98G [00:23<01:33, 76.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.98G [00:25<04:37, 25.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.84G/9.98G [00:25<03:03, 38.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.86G/9.98G [00:25<02:31, 47.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.88G/9.98G [00:25<02:02, 58.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.98G [00:25<01:37, 72.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.94G/9.98G [00:26<01:22, 85.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.96G/9.98G [00:26<01:13, 95.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.98G/9.98G [00:26<01:03, 110MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.00G/9.98G [00:26<00:57, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.02G/9.98G [00:26<00:53, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.04G/9.98G [00:26<00:51, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.98G [00:27<00:54, 127MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.08G/9.98G [00:27<01:01, 112MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.10G/9.98G [00:27<00:54, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.12G/9.98G [00:27<00:51, 132MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.15G/9.98G [00:27<00:46, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.17G/9.98G [00:27<00:42, 160MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.98G [00:27<00:42, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.21G/9.98G [00:28<00:42, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.23G/9.98G [00:28<00:44, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.25G/9.98G [00:28<00:52, 127MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.27G/9.98G [00:28<00:56, 118MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.29G/9.98G [00:30<03:23, 32.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.31G/9.98G [00:30<02:36, 42.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.33G/9.98G [00:30<02:01, 54.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.36G/9.98G [00:30<01:36, 68.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.38G/9.98G [00:30<01:18, 84.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.40G/9.98G [00:31<01:04, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.43G/9.98G [00:31<00:51, 128MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [00:31<00:47, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.47G/9.98G [00:31<00:46, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.49G/9.98G [00:31<00:42, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.51G/9.98G [00:31<00:39, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.53G/9.98G [00:31<00:37, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.55G/9.98G [00:32<00:54, 117MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.59G/9.98G [00:32<00:45, 142MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.62G/9.98G [00:32<00:39, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.64G/9.98G [00:32<00:39, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.98G [00:32<00:38, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.68G/9.98G [00:32<00:37, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [00:32<00:36, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.72G/9.98G [00:32<00:35, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.74G/9.98G [00:33<00:35, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.76G/9.98G [00:33<00:34, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.79G/9.98G [00:33<00:33, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.81G/9.98G [00:33<00:33, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.83G/9.98G [00:33<00:33, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.85G/9.98G [00:33<00:34, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.87G/9.98G [00:33<00:34, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.89G/9.98G [00:33<00:32, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.91G/9.98G [00:33<00:32, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.93G/9.98G [00:34<00:31, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.96G/9.98G [00:34<00:30, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.98G/9.98G [00:34<00:29, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.01G/9.98G [00:34<00:29, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.04G/9.98G [00:34<00:28, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.06G/9.98G [00:34<00:29, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.08G/9.98G [00:34<00:31, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.10G/9.98G [00:34<00:31, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.12G/9.98G [00:35<00:31, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.14G/9.98G [00:35<00:31, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.16G/9.98G [00:35<00:37, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.18G/9.98G [00:35<00:35, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.20G/9.98G [00:35<00:35, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.23G/9.98G [00:35<00:33, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.25G/9.98G [00:35<00:31, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.27G/9.98G [00:35<00:30, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.30G/9.98G [00:36<00:28, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.33G/9.98G [00:36<00:28, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.35G/9.98G [00:36<00:28, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.37G/9.98G [00:36<00:29, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.39G/9.98G [00:36<00:30, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.41G/9.98G [00:36<00:30, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.44G/9.98G [00:36<00:29, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.46G/9.98G [00:36<00:28, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.49G/9.98G [00:37<00:27, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.51G/9.98G [00:37<00:27, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.53G/9.98G [00:37<00:28, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.55G/9.98G [00:37<00:28, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.57G/9.98G [00:37<00:29, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.59G/9.98G [00:37<00:28, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.61G/9.98G [00:37<00:28, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.63G/9.98G [00:40<03:44, 23.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.66G/9.98G [00:40<02:48, 31.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.69G/9.98G [00:40<01:51, 47.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.72G/9.98G [00:40<01:22, 64.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.74G/9.98G [00:41<01:13, 71.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.76G/9.98G [00:41<01:00, 86.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.78G/9.98G [00:41<00:54, 95.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.80G/9.98G [00:41<00:56, 92.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.82G/9.98G [00:41<00:48, 107MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.84G/9.98G [00:41<00:44, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.87G/9.98G [00:42<00:52, 96.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.89G/9.98G [00:42<00:44, 113MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.91G/9.98G [00:42<00:50, 100MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.93G/9.98G [00:42<00:53, 93.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.95G/9.98G [00:42<00:45, 110MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.97G/9.98G [00:43<00:43, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.99G/9.98G [00:43<00:39, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.01G/9.98G [00:43<00:35, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.03G/9.98G [00:43<00:38, 127MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.05G/9.98G [00:43<00:38, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.08G/9.98G [00:43<00:41, 117MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.10G/9.98G [00:45<02:13, 36.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.13G/9.98G [00:45<01:30, 53.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.15G/9.98G [00:45<01:16, 63.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.17G/9.98G [00:45<01:03, 75.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.20G/9.98G [00:46<00:48, 99.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.22G/9.98G [00:46<00:41, 115MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.24G/9.98G [00:46<00:37, 128MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.26G/9.98G [00:46<00:35, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.28G/9.98G [00:46<00:33, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.31G/9.98G [00:46<00:30, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.33G/9.98G [00:46<00:28, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.36G/9.98G [00:46<00:25, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.39G/9.98G [00:47<00:23, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.42G/9.98G [00:47<00:23, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.44G/9.98G [00:47<00:24, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.46G/9.98G [00:47<00:24, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.48G/9.98G [00:47<00:23, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.51G/9.98G [00:47<00:22, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.53G/9.98G [00:47<00:22, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.56G/9.98G [00:47<00:21, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.58G/9.98G [00:48<00:24, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.60G/9.98G [00:48<00:24, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.62G/9.98G [00:48<00:24, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.64G/9.98G [00:48<00:23, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.66G/9.98G [00:48<00:23, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.68G/9.98G [00:50<02:12, 32.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.70G/9.98G [00:50<01:39, 42.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.73G/9.98G [00:50<01:17, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.75G/9.98G [00:50<01:05, 64.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.77G/9.98G [00:50<00:52, 80.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.79G/9.98G [00:51<00:42, 97.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.81G/9.98G [00:51<00:36, 114MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.83G/9.98G [00:51<00:32, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.85G/9.98G [00:51<00:30, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.87G/9.98G [00:51<00:42, 97.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.89G/9.98G [00:51<00:35, 114MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.91G/9.98G [00:51<00:30, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.93G/9.98G [00:52<00:27, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.96G/9.98G [00:52<00:25, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.98G/9.98G [00:52<00:24, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.00G/9.98G [00:52<00:25, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.02G/9.98G [00:52<00:25, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.04G/9.98G [00:52<00:25, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.06G/9.98G [00:52<00:25, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.08G/9.98G [00:53<00:25, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.10G/9.98G [00:55<02:27, 26.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.12G/9.98G [00:55<01:48, 35.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.14G/9.98G [00:55<01:29, 43.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.17G/9.98G [00:55<01:07, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.20G/9.98G [00:55<00:49, 76.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.23G/9.98G [00:56<00:37, 100MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.25G/9.98G [00:56<00:36, 101MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.27G/9.98G [00:56<00:32, 113MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.29G/9.98G [00:56<00:34, 108MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.31G/9.98G [00:56<00:29, 123MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.33G/9.98G [00:56<00:27, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.35G/9.98G [00:57<00:24, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.98G [00:57<00:23, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.40G/9.98G [00:57<00:23, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.42G/9.98G [00:57<00:26, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.44G/9.98G [00:57<00:28, 124MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.47G/9.98G [00:57<00:23, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.49G/9.98G [00:57<00:21, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.52G/9.98G [00:58<00:20, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.54G/9.98G [00:58<00:21, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.56G/9.98G [00:58<00:20, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.59G/9.98G [00:58<00:19, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.61G/9.98G [00:58<00:18, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.63G/9.98G [00:58<00:18, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.65G/9.98G [01:00<01:32, 35.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.67G/9.98G [01:00<01:09, 47.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.69G/9.98G [01:00<00:54, 60.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.71G/9.98G [01:00<00:46, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.73G/9.98G [01:00<00:37, 85.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.75G/9.98G [01:01<00:30, 104MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.78G/9.98G [01:01<00:24, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.81G/9.98G [01:01<00:23, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.83G/9.98G [01:01<00:21, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.98G [01:01<00:20, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.87G/9.98G [01:01<00:18, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.90G/9.98G [01:01<00:16, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.93G/9.98G [01:01<00:15, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.95G/9.98G [01:02<00:15, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.97G/9.98G [01:02<00:15, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.99G/9.98G [01:02<00:15, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.01G/9.98G [01:02<00:16, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.04G/9.98G [01:02<00:15, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.06G/9.98G [01:05<02:06, 23.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.08G/9.98G [01:05<01:33, 31.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.10G/9.98G [01:05<01:09, 41.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.13G/9.98G [01:05<00:47, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.16G/9.98G [01:05<00:34, 81.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.18G/9.98G [01:06<00:31, 88.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.21G/9.98G [01:06<00:24, 111MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.24G/9.98G [01:06<00:28, 96.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.26G/9.98G [01:06<00:24, 111MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.28G/9.98G [01:06<00:21, 123MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.30G/9.98G [01:06<00:19, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.32G/9.98G [01:06<00:18, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.34G/9.98G [01:07<00:17, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.37G/9.98G [01:07<00:15, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.39G/9.98G [01:07<00:14, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.42G/9.98G [01:07<00:13, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.44G/9.98G [01:07<00:14, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.47G/9.98G [01:07<00:14, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.49G/9.98G [01:07<00:13, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.51G/9.98G [01:07<00:13, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.53G/9.98G [01:09<00:57, 42.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.55G/9.98G [01:11<01:42, 23.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.58G/9.98G [01:11<01:06, 36.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [01:11<00:53, 44.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.63G/9.98G [01:11<00:37, 62.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.65G/9.98G [01:11<00:32, 71.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.68G/9.98G [01:12<00:30, 74.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.70G/9.98G [01:12<00:30, 75.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.72G/9.98G [01:12<00:28, 79.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.75G/9.98G [01:12<00:22, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.77G/9.98G [01:12<00:21, 100MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.79G/9.98G [01:13<00:20, 105MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.81G/9.98G [01:13<00:23, 90.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.83G/9.98G [01:13<00:19, 108MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.86G/9.98G [01:13<00:15, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.90G/9.98G [01:13<00:13, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.92G/9.98G [01:13<00:12, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.94G/9.98G [01:14<00:12, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.96G/9.98G [01:14<00:12, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.98G/9.98G [01:14<00:12, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.00G/9.98G [01:14<00:11, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.02G/9.98G [01:14<00:11, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.04G/9.98G [01:14<00:10, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.06G/9.98G [01:14<00:10, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.08G/9.98G [01:14<00:10, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.11G/9.98G [01:15<00:10, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.13G/9.98G [01:15<00:10, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.15G/9.98G [01:15<00:11, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.17G/9.98G [01:15<00:11, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.19G/9.98G [01:15<00:10, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.21G/9.98G [01:15<00:10, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.23G/9.98G [01:15<00:09, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.25G/9.98G [01:15<00:09, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.27G/9.98G [01:16<00:10, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.29G/9.98G [01:16<00:10, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.32G/9.98G [01:16<00:10, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.34G/9.98G [01:16<00:10, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.36G/9.98G [01:16<00:10, 160MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.38G/9.98G [01:16<00:09, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.40G/9.98G [01:16<00:09, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.42G/9.98G [01:16<00:08, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.44G/9.98G [01:17<00:08, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.46G/9.98G [01:17<00:08, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [01:17<00:09, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.50G/9.98G [01:17<00:09, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.54G/9.98G [01:17<00:08, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.57G/9.98G [01:17<00:07, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.60G/9.98G [01:17<00:07, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.62G/9.98G [01:18<00:07, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.64G/9.98G [01:18<00:07, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.66G/9.98G [01:18<00:07, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.68G/9.98G [01:18<00:07, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [01:18<00:07, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.72G/9.98G [01:20<00:37, 33.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.75G/9.98G [01:20<00:28, 44.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.77G/9.98G [01:20<00:21, 56.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.80G/9.98G [01:20<00:14, 79.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.82G/9.98G [01:20<00:12, 95.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.84G/9.98G [01:20<00:10, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.86G/9.98G [01:21<00:09, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.89G/9.98G [01:21<00:07, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.91G/9.98G [01:21<00:07, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.93G/9.98G [01:21<00:06, 151MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.95G/9.98G [01:21<00:06, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.99G/9.98G [01:21<00:05, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.02G/9.98G [01:21<00:05, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [01:22<00:04, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.07G/9.98G [01:22<00:04, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.09G/9.98G [01:22<00:04, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.11G/9.98G [01:22<00:04, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.13G/9.98G [01:22<00:04, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.15G/9.98G [01:23<00:12, 65.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.18G/9.98G [01:25<00:31, 25.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.20G/9.98G [01:25<00:22, 34.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.22G/9.98G [01:25<00:17, 44.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.24G/9.98G [01:25<00:13, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.26G/9.98G [01:25<00:10, 70.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.29G/9.98G [01:26<00:07, 94.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.31G/9.98G [01:26<00:06, 110MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.33G/9.98G [01:26<00:05, 117MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.35G/9.98G [01:26<00:04, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.38G/9.98G [01:26<00:03, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.41G/9.98G [01:26<00:03, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.43G/9.98G [01:26<00:03, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.45G/9.98G [01:26<00:03, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.47G/9.98G [01:27<00:03, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.49G/9.98G [01:27<00:02, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.51G/9.98G [01:27<00:02, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.53G/9.98G [01:28<00:06, 71.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [01:30<00:18, 23.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.58G/9.98G [01:30<00:11, 34.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.60G/9.98G [01:30<00:08, 42.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.63G/9.98G [01:30<00:06, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.65G/9.98G [01:31<00:04, 68.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.67G/9.98G [01:31<00:03, 85.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.69G/9.98G [01:31<00:02, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.71G/9.98G [01:31<00:02, 113MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.73G/9.98G [01:31<00:01, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.75G/9.98G [01:31<00:01, 143MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.77G/9.98G [01:31<00:01, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.79G/9.98G [01:31<00:01, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.83G/9.98G [01:31<00:00, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.85G/9.98G [01:32<00:00, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.87G/9.98G [01:32<00:00, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.89G/9.98G [01:32<00:00, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.91G/9.98G [01:32<00:00, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.93G/9.98G [01:32<00:00, 98.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.95G/9.98G [01:35<00:01, 22.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [01:35<00:00, 104MB/s] \n",
            "Downloading shards:  50% 1/2 [01:35<01:35, 95.94s/it]\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 21.0M/3.50G [00:00<00:18, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 52.4M/3.50G [00:00<00:16, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 83.9M/3.50G [00:00<00:17, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 105M/3.50G [00:00<00:18, 188MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 126M/3.50G [00:00<00:18, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 147M/3.50G [00:00<00:18, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 168M/3.50G [00:01<00:29, 113MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 189M/3.50G [00:01<00:25, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 220M/3.50G [00:01<00:21, 155MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 252M/3.50G [00:01<00:18, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 273M/3.50G [00:01<00:17, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 294M/3.50G [00:01<00:18, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 315M/3.50G [00:01<00:18, 173MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 336M/3.50G [00:01<00:18, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 357M/3.50G [00:02<00:17, 178MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 377M/3.50G [00:02<00:17, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 398M/3.50G [00:05<02:27, 21.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 430M/3.50G [00:05<01:34, 32.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 461M/3.50G [00:05<01:05, 46.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 493M/3.50G [00:05<00:47, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 514M/3.50G [00:05<00:39, 75.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 535M/3.50G [00:05<00:33, 88.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 556M/3.50G [00:06<00:29, 99.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 577M/3.50G [00:06<00:26, 112MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 598M/3.50G [00:06<00:23, 124MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 619M/3.50G [00:06<00:21, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 640M/3.50G [00:06<00:19, 150MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 661M/3.50G [00:06<00:17, 162MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 682M/3.50G [00:06<00:16, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 713M/3.50G [00:06<00:15, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 744M/3.50G [00:07<00:14, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 765M/3.50G [00:07<00:13, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 786M/3.50G [00:07<00:13, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 807M/3.50G [00:07<00:14, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 828M/3.50G [00:07<00:14, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 849M/3.50G [00:07<00:14, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 870M/3.50G [00:07<00:14, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 891M/3.50G [00:07<00:14, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 912M/3.50G [00:09<01:11, 36.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 944M/3.50G [00:09<00:48, 53.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 965M/3.50G [00:09<00:41, 61.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 986M/3.50G [00:10<00:33, 74.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.01G/3.50G [00:10<00:27, 90.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.03G/3.50G [00:10<00:22, 108MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.05G/3.50G [00:10<00:21, 114MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.07G/3.50G [00:10<00:19, 124MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.09G/3.50G [00:10<00:17, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.11G/3.50G [00:10<00:16, 147MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.13G/3.50G [00:10<00:14, 159MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.15G/3.50G [00:11<00:17, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.17G/3.50G [00:11<00:17, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.20G/3.50G [00:11<00:20, 113MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.22G/3.50G [00:11<00:21, 106MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.24G/3.50G [00:12<00:23, 98.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.26G/3.50G [00:12<00:23, 94.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.28G/3.50G [00:12<00:22, 100MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.30G/3.50G [00:12<00:20, 110MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:13<00:36, 59.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.33G/3.50G [00:14<01:15, 28.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.36G/3.50G [00:14<00:46, 45.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.38G/3.50G [00:14<00:37, 56.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.41G/3.50G [00:15<00:31, 67.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.43G/3.50G [00:15<00:24, 83.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.45G/3.50G [00:15<00:20, 100MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.47G/3.50G [00:15<00:18, 112MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.49G/3.50G [00:15<00:16, 122MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.51G/3.50G [00:15<00:15, 129MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.53G/3.50G [00:15<00:14, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.55G/3.50G [00:15<00:12, 150MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.57G/3.50G [00:16<00:11, 161MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.59G/3.50G [00:16<00:11, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.61G/3.50G [00:16<00:10, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.64G/3.50G [00:16<00:11, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.66G/3.50G [00:16<00:12, 152MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.68G/3.50G [00:16<00:11, 159MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.70G/3.50G [00:16<00:11, 162MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.72G/3.50G [00:16<00:10, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.74G/3.50G [00:16<00:09, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.76G/3.50G [00:17<00:10, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.78G/3.50G [00:17<00:09, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.80G/3.50G [00:17<00:09, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.82G/3.50G [00:17<00:09, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.85G/3.50G [00:17<00:08, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.88G/3.50G [00:17<00:08, 194MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.90G/3.50G [00:17<00:08, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.92G/3.50G [00:17<00:08, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.94G/3.50G [00:18<00:08, 194MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.97G/3.50G [00:18<00:07, 202MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 1.99G/3.50G [00:18<00:07, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.02G/3.50G [00:18<00:07, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.06G/3.50G [00:18<00:06, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.08G/3.50G [00:18<00:06, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.10G/3.50G [00:18<00:07, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.12G/3.50G [00:18<00:07, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.14G/3.50G [00:19<00:07, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.16G/3.50G [00:19<00:07, 191MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.19G/3.50G [00:19<00:06, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.21G/3.50G [00:19<00:06, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.23G/3.50G [00:19<00:06, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.25G/3.50G [00:19<00:06, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.28G/3.50G [00:19<00:06, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.30G/3.50G [00:19<00:06, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.33G/3.50G [00:20<00:05, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.36G/3.50G [00:20<00:05, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.38G/3.50G [00:20<00:05, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.40G/3.50G [00:20<00:06, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.43G/3.50G [00:20<00:05, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.45G/3.50G [00:20<00:05, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.49G/3.50G [00:20<00:05, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.52G/3.50G [00:21<00:05, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.54G/3.50G [00:21<00:05, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.56G/3.50G [00:21<00:05, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.58G/3.50G [00:21<00:04, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.60G/3.50G [00:21<00:04, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.62G/3.50G [00:21<00:04, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.64G/3.50G [00:21<00:04, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.66G/3.50G [00:21<00:04, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.68G/3.50G [00:21<00:04, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.71G/3.50G [00:22<00:04, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.74G/3.50G [00:22<00:03, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.76G/3.50G [00:22<00:03, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.79G/3.50G [00:22<00:03, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.81G/3.50G [00:22<00:05, 131MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.83G/3.50G [00:22<00:04, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.85G/3.50G [00:22<00:04, 150MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.87G/3.50G [00:23<00:03, 157MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.89G/3.50G [00:23<00:03, 165MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.92G/3.50G [00:24<00:12, 48.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.94G/3.50G [00:24<00:10, 56.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.96G/3.50G [00:24<00:07, 71.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.98G/3.50G [00:24<00:07, 74.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.00G/3.50G [00:25<00:06, 83.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.02G/3.50G [00:25<00:04, 97.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.04G/3.50G [00:25<00:05, 91.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.06G/3.50G [00:25<00:04, 106MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.08G/3.50G [00:25<00:03, 112MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.10G/3.50G [00:25<00:03, 123MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.12G/3.50G [00:26<00:03, 117MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.15G/3.50G [00:26<00:03, 106MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.17G/3.50G [00:26<00:02, 120MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.20G/3.50G [00:26<00:02, 146MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.23G/3.50G [00:26<00:01, 165MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.25G/3.50G [00:26<00:01, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.27G/3.50G [00:27<00:01, 130MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.29G/3.50G [00:27<00:01, 124MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.31G/3.50G [00:27<00:01, 99.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.33G/3.50G [00:27<00:01, 101MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.36G/3.50G [00:29<00:04, 33.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.38G/3.50G [00:29<00:02, 42.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.40G/3.50G [00:29<00:01, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.42G/3.50G [00:30<00:01, 64.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.44G/3.50G [00:30<00:00, 81.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.46G/3.50G [00:30<00:00, 80.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [00:30<00:00, 114MB/s]\n",
            "Downloading shards: 100% 2/2 [02:06<00:00, 63.40s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [01:01<00:00, 30.71s/it]\n",
            "generation_config.json: 100% 174/174 [00:00<00:00, 868kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 1.62k/1.62k [00:00<00:00, 5.69MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 11.5MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 30.5MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 1.83MB/s]\n",
            "The model `jizzu/llama-2-7b-chat-law-finetune` and tokenizer `meta-llama/Llama-2-7b-chat-hf` are different, please ensure that they are compatible.\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/embeddings/__init__.py:29: LangChainDeprecationWarning: Importing embeddings from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.embeddings import HuggingFaceEmbeddings`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "modules.json: 100% 349/349 [00:00<00:00, 1.41MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 486kB/s]\n",
            "README.md: 100% 10.6k/10.6k [00:00<00:00, 33.7MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 290kB/s]\n",
            "config.json: 100% 571/571 [00:00<00:00, 3.59MB/s]\n",
            "model.safetensors: 100% 438M/438M [00:02<00:00, 161MB/s]\n",
            "tokenizer_config.json: 100% 363/363 [00:00<00:00, 1.38MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 44.7MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 6.33MB/s]\n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 1.43MB/s]\n",
            "1_Pooling/config.json: 100% 190/190 [00:00<00:00, 893kB/s]\n",
            "/content/streamlit_llamaindex_final.py:57: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context=ServiceContext.from_defaults(\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100% 2/2 [00:59<00:00, 29.91s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "The model `jizzu/llama-2-7b-chat-law-finetune` and tokenizer `meta-llama/Llama-2-7b-chat-hf` are different, please ensure that they are compatible.\n",
            "/content/streamlit_llamaindex_final.py:57: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context=ServiceContext.from_defaults(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n",
            "2024-04-18 06:55:11.663769: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-18 06:55:11.663831: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-18 06:55:11.786772: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-18 06:55:14.215198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "2024-04-18 07:02:50.330 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 584, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/streamlit_llamaindex_final.py\", line 34, in <module>\n",
            "    llm = HuggingFaceLLM(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/llama_index/llms/huggingface/base.py\", line 161, in __init__\n",
            "    self._model = model or AutoModelForCausalLM.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 561, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3452, in from_pretrained\n",
            "    hf_quantizer.validate_environment(device_map=device_map)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\", line 86, in validate_environment\n",
            "    raise ValueError(\n",
            "ValueError: \n",
            "                    Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the\n",
            "                    quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules\n",
            "                    in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to\n",
            "                    `from_pretrained`. Check\n",
            "                    https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n",
            "                    for more details.\n",
            "                    \n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n",
        "! streamlit run streamlit_llamaindex_final.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yugWG-_kMPnj",
        "outputId": "c9caa3f9-7ad9-407b-f9a6-a0c2c76e44ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.83.56.137\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.83.56.137:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.722s\n",
            "your url is: https://forty-llamas-judge.loca.lt\n",
            "config.json: 100% 632/632 [00:00<00:00, 3.02MB/s]\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 64.1MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 21.0M/9.98G [00:00<01:05, 151MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 52.4M/9.98G [00:00<00:51, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 83.9M/9.98G [00:00<00:45, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 115M/9.98G [00:00<00:43, 226MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 147M/9.98G [00:00<00:48, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 178M/9.98G [00:00<00:46, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 210M/9.98G [00:00<00:45, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 241M/9.98G [00:01<00:49, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 262M/9.98G [00:01<00:49, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 283M/9.98G [00:01<00:50, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 304M/9.98G [00:01<00:49, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 325M/9.98G [00:01<00:50, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 346M/9.98G [00:01<00:50, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 367M/9.98G [00:01<00:51, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 388M/9.98G [00:01<00:50, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 409M/9.98G [00:02<00:49, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 430M/9.98G [00:02<00:48, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 461M/9.98G [00:02<00:45, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 493M/9.98G [00:02<00:44, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 524M/9.98G [00:02<00:43, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 556M/9.98G [00:02<00:42, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 587M/9.98G [00:02<00:46, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 608M/9.98G [00:03<00:45, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 640M/9.98G [00:03<00:45, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 671M/9.98G [00:03<00:44, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 703M/9.98G [00:03<00:43, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 734M/9.98G [00:03<00:43, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 765M/9.98G [00:03<00:41, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 797M/9.98G [00:03<00:40, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 828M/9.98G [00:03<00:40, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 860M/9.98G [00:04<00:39, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 891M/9.98G [00:04<00:39, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 923M/9.98G [00:04<00:40, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 954M/9.98G [00:04<00:40, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 986M/9.98G [00:05<02:29, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.01G/9.98G [00:07<03:35, 41.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.03G/9.98G [00:07<02:59, 49.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.05G/9.98G [00:07<02:25, 61.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.07G/9.98G [00:07<01:57, 75.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.10G/9.98G [00:07<01:27, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.13G/9.98G [00:07<01:10, 126MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.16G/9.98G [00:07<00:59, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.20G/9.98G [00:07<00:54, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.22G/9.98G [00:08<00:51, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.24G/9.98G [00:08<00:50, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.26G/9.98G [00:08<00:48, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.29G/9.98G [00:08<00:43, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.32G/9.98G [00:08<00:41, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.35G/9.98G [00:08<00:39, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.38G/9.98G [00:08<00:38, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.42G/9.98G [00:10<02:29, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.44G/9.98G [00:10<02:09, 65.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.46G/9.98G [00:10<01:47, 79.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.49G/9.98G [00:10<01:21, 104MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.52G/9.98G [00:10<01:05, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.55G/9.98G [00:10<00:56, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.58G/9.98G [00:11<00:51, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.61G/9.98G [00:11<00:47, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.65G/9.98G [00:11<00:44, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.68G/9.98G [00:11<00:42, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.71G/9.98G [00:11<00:40, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.74G/9.98G [00:11<00:39, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.77G/9.98G [00:11<00:39, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.80G/9.98G [00:12<00:38, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.84G/9.98G [00:12<00:36, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [00:12<00:35, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.90G/9.98G [00:12<00:33, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [00:12<00:33, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.96G/9.98G [00:12<00:32, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.99G/9.98G [00:12<00:36, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.02G/9.98G [00:14<02:11, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.04G/9.98G [00:16<05:30, 24.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.08G/9.98G [00:17<03:53, 33.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.10G/9.98G [00:17<03:09, 41.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.12G/9.98G [00:17<02:37, 50.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.14G/9.98G [00:17<02:07, 61.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [00:17<01:43, 75.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.19G/9.98G [00:17<01:16, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.21G/9.98G [00:17<01:07, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.23G/9.98G [00:17<01:00, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.25G/9.98G [00:18<00:55, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.28G/9.98G [00:18<00:50, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.30G/9.98G [00:18<00:47, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.32G/9.98G [00:18<00:45, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.34G/9.98G [00:18<00:42, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.37G/9.98G [00:18<00:39, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.40G/9.98G [00:18<00:37, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.43G/9.98G [00:18<00:35, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.46G/9.98G [00:19<00:50, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.50G/9.98G [00:19<00:43, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.53G/9.98G [00:19<00:38, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.98G [00:19<00:35, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.59G/9.98G [00:19<00:36, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.62G/9.98G [00:19<00:36, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.65G/9.98G [00:20<00:34, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.98G [00:20<00:35, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.72G/9.98G [00:20<00:34, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [00:20<00:32, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.78G/9.98G [00:20<00:31, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.98G [00:20<00:30, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.84G/9.98G [00:21<00:37, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.86G/9.98G [00:21<00:37, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.88G/9.98G [00:21<00:37, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.98G [00:21<00:40, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.93G/9.98G [00:21<00:39, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.95G/9.98G [00:21<00:37, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.97G/9.98G [00:21<00:59, 117MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.00G/9.98G [00:22<00:48, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.03G/9.98G [00:22<00:40, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.98G [00:22<00:36, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.09G/9.98G [00:22<00:41, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.11G/9.98G [00:22<00:40, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.15G/9.98G [00:22<00:37, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.17G/9.98G [00:22<00:36, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.98G [00:23<00:35, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.21G/9.98G [00:23<00:35, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.24G/9.98G [00:23<00:33, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.27G/9.98G [00:23<00:32, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.29G/9.98G [00:23<00:32, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.32G/9.98G [00:23<00:30, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.36G/9.98G [00:23<00:30, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.39G/9.98G [00:23<00:29, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.42G/9.98G [00:24<00:28, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [00:24<00:27, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.48G/9.98G [00:24<00:27, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.51G/9.98G [00:24<00:29, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.54G/9.98G [00:24<00:31, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.57G/9.98G [00:24<00:32, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.59G/9.98G [00:24<00:32, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.61G/9.98G [00:26<03:02, 34.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.64G/9.98G [00:27<02:05, 50.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.98G [00:27<01:44, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.68G/9.98G [00:27<01:30, 69.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [00:27<01:14, 84.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.72G/9.98G [00:27<01:01, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.75G/9.98G [00:27<00:48, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.77G/9.98G [00:27<00:45, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.80G/9.98G [00:27<00:41, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.83G/9.98G [00:28<00:35, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.86G/9.98G [00:28<00:33, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.89G/9.98G [00:28<00:30, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.92G/9.98G [00:28<00:29, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.95G/9.98G [00:28<00:31, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.97G/9.98G [00:28<00:31, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.01G/9.98G [00:28<00:29, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.04G/9.98G [00:29<00:27, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.07G/9.98G [00:29<00:26, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.10G/9.98G [00:29<00:26, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.13G/9.98G [00:29<00:28, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.16G/9.98G [00:29<00:27, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.19G/9.98G [00:31<02:23, 40.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.23G/9.98G [00:32<01:47, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.26G/9.98G [00:32<01:21, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.29G/9.98G [00:32<01:06, 86.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.31G/9.98G [00:32<01:00, 93.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.33G/9.98G [00:32<00:53, 105MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.35G/9.98G [00:32<00:46, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.38G/9.98G [00:32<00:39, 143MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.40G/9.98G [00:33<00:37, 150MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.42G/9.98G [00:33<00:34, 160MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.45G/9.98G [00:33<00:32, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.47G/9.98G [00:33<00:31, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.50G/9.98G [00:33<00:28, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.53G/9.98G [00:33<00:26, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.56G/9.98G [00:33<00:25, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.59G/9.98G [00:33<00:25, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.62G/9.98G [00:34<00:23, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.66G/9.98G [00:34<00:23, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.69G/9.98G [00:34<00:22, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.72G/9.98G [00:34<00:23, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.75G/9.98G [00:35<01:33, 56.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.77G/9.98G [00:36<01:20, 64.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.79G/9.98G [00:36<01:10, 73.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.81G/9.98G [00:36<01:02, 82.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.83G/9.98G [00:36<01:20, 64.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.85G/9.98G [00:37<01:07, 76.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.88G/9.98G [00:37<00:59, 85.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.90G/9.98G [00:37<00:50, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.92G/9.98G [00:37<00:42, 118MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.94G/9.98G [00:37<00:38, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.96G/9.98G [00:37<00:34, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.99G/9.98G [00:37<00:29, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.02G/9.98G [00:37<00:27, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.04G/9.98G [00:38<00:26, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.06G/9.98G [00:38<00:27, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.09G/9.98G [00:38<00:28, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.11G/9.98G [00:38<00:28, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.13G/9.98G [00:38<00:28, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.15G/9.98G [00:38<00:27, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.18G/9.98G [00:38<00:24, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.20G/9.98G [00:38<00:24, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.23G/9.98G [00:39<00:22, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.26G/9.98G [00:39<00:21, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.30G/9.98G [00:39<00:20, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.33G/9.98G [00:39<00:20, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.36G/9.98G [00:39<00:20, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.39G/9.98G [00:39<00:20, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.42G/9.98G [00:39<00:20, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.45G/9.98G [00:40<00:21, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.48G/9.98G [00:40<00:20, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.52G/9.98G [00:40<00:20, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.55G/9.98G [00:40<00:20, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.58G/9.98G [00:40<00:20, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.61G/9.98G [00:40<00:20, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.64G/9.98G [00:41<01:00, 71.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.67G/9.98G [00:42<00:48, 89.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.70G/9.98G [00:42<00:38, 111MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.74G/9.98G [00:42<00:32, 132MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.77G/9.98G [00:42<00:29, 143MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.79G/9.98G [00:42<00:30, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.81G/9.98G [00:42<00:28, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.84G/9.98G [00:42<00:25, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.86G/9.98G [00:43<00:25, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.88G/9.98G [00:43<00:24, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.90G/9.98G [00:43<00:23, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.92G/9.98G [00:43<00:22, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.96G/9.98G [00:43<00:21, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.99G/9.98G [00:43<00:19, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.01G/9.98G [00:43<00:19, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.04G/9.98G [00:43<00:18, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.07G/9.98G [00:44<00:17, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.10G/9.98G [00:44<00:16, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.13G/9.98G [00:44<00:17, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.17G/9.98G [00:44<00:17, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.20G/9.98G [00:44<00:17, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.23G/9.98G [00:46<01:35, 39.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.26G/9.98G [00:47<01:10, 52.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.28G/9.98G [00:47<00:58, 62.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.30G/9.98G [00:47<00:51, 71.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.32G/9.98G [00:47<00:43, 83.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.34G/9.98G [00:47<00:36, 99.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.98G [00:47<00:29, 124MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.40G/9.98G [00:47<00:27, 132MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.42G/9.98G [00:47<00:25, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.45G/9.98G [00:48<00:22, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.47G/9.98G [00:48<00:21, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.49G/9.98G [00:48<00:21, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.51G/9.98G [00:48<00:20, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.54G/9.98G [00:48<00:17, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.57G/9.98G [00:48<00:16, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.61G/9.98G [00:48<00:18, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.63G/9.98G [00:49<00:18, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.65G/9.98G [00:49<00:18, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.67G/9.98G [00:49<00:18, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.69G/9.98G [00:49<00:18, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.71G/9.98G [00:49<00:17, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.74G/9.98G [00:49<00:16, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.77G/9.98G [00:50<00:23, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.81G/9.98G [00:50<00:20, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.83G/9.98G [00:50<00:19, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.98G [00:50<00:20, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.87G/9.98G [00:50<00:19, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.89G/9.98G [00:50<00:18, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.91G/9.98G [00:50<00:18, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.93G/9.98G [00:50<00:17, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.95G/9.98G [00:51<00:17, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.97G/9.98G [00:51<00:52, 57.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.00G/9.98G [00:52<00:36, 81.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.03G/9.98G [00:52<00:32, 91.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.05G/9.98G [00:52<00:28, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.07G/9.98G [00:52<00:25, 114MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.10G/9.98G [00:52<00:20, 142MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.13G/9.98G [00:52<00:18, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.15G/9.98G [00:52<00:17, 160MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.17G/9.98G [00:53<00:16, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.20G/9.98G [00:53<00:15, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.24G/9.98G [00:53<00:14, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.27G/9.98G [00:53<00:13, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.30G/9.98G [00:53<00:12, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.33G/9.98G [00:53<00:12, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.36G/9.98G [00:53<00:11, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.39G/9.98G [00:54<00:11, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.42G/9.98G [00:54<00:10, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.46G/9.98G [00:54<00:10, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.49G/9.98G [00:54<00:10, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.52G/9.98G [00:54<00:10, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.55G/9.98G [00:54<00:11, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.58G/9.98G [00:54<00:11, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.61G/9.98G [00:56<00:54, 43.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.64G/9.98G [00:57<00:40, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.68G/9.98G [00:57<00:31, 74.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.71G/9.98G [00:57<00:24, 94.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.74G/9.98G [00:57<00:20, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.76G/9.98G [00:57<00:19, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.78G/9.98G [00:57<00:17, 125MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.81G/9.98G [00:57<00:15, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.83G/9.98G [00:58<00:14, 148MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.86G/9.98G [00:58<00:12, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.90G/9.98G [00:58<00:11, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.92G/9.98G [00:58<00:11, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [00:58<00:10, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.98G/9.98G [00:58<00:09, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.01G/9.98G [00:58<00:09, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.04G/9.98G [00:59<00:08, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.07G/9.98G [00:59<00:08, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.11G/9.98G [00:59<00:07, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.14G/9.98G [00:59<00:07, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.17G/9.98G [00:59<00:08, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.20G/9.98G [00:59<00:08, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.23G/9.98G [00:59<00:08, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.26G/9.98G [01:00<00:08, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.29G/9.98G [01:00<00:07, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.33G/9.98G [01:00<00:07, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.36G/9.98G [01:00<00:07, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.39G/9.98G [01:00<00:07, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.42G/9.98G [01:00<00:06, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.45G/9.98G [01:00<00:06, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [01:00<00:06, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.51G/9.98G [01:01<00:06, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.55G/9.98G [01:01<00:05, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.58G/9.98G [01:01<00:05, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.61G/9.98G [01:01<00:06, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.64G/9.98G [01:01<00:06, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.66G/9.98G [01:01<00:06, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.69G/9.98G [01:02<00:06, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.72G/9.98G [01:02<00:06, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.76G/9.98G [01:02<00:05, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.79G/9.98G [01:02<00:06, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.81G/9.98G [01:02<00:06, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.83G/9.98G [01:02<00:06, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.85G/9.98G [01:02<00:06, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.87G/9.98G [01:03<00:06, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.89G/9.98G [01:03<00:06, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.91G/9.98G [01:03<00:05, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.93G/9.98G [01:03<00:05, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.95G/9.98G [01:03<00:05, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.98G/9.98G [01:03<00:05, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.01G/9.98G [01:03<00:04, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.03G/9.98G [01:03<00:04, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [01:03<00:04, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.07G/9.98G [01:04<00:05, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.09G/9.98G [01:04<00:05, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.11G/9.98G [01:04<00:05, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.13G/9.98G [01:04<00:04, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.16G/9.98G [01:04<00:04, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.20G/9.98G [01:04<00:03, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.23G/9.98G [01:04<00:03, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.26G/9.98G [01:04<00:03, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.29G/9.98G [01:05<00:03, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.32G/9.98G [01:05<00:02, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.35G/9.98G [01:05<00:02, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.38G/9.98G [01:05<00:02, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.42G/9.98G [01:05<00:02, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.45G/9.98G [01:05<00:02, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.48G/9.98G [01:05<00:02, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.51G/9.98G [01:06<00:03, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.53G/9.98G [01:06<00:05, 83.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [01:07<00:04, 97.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.58G/9.98G [01:07<00:03, 120MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.62G/9.98G [01:07<00:02, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.65G/9.98G [01:07<00:01, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.68G/9.98G [01:07<00:01, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.71G/9.98G [01:07<00:01, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.74G/9.98G [01:07<00:01, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.76G/9.98G [01:08<00:01, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.78G/9.98G [01:08<00:01, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.80G/9.98G [01:08<00:00, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [01:08<00:00, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.86G/9.98G [01:08<00:00, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.88G/9.98G [01:08<00:00, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.91G/9.98G [01:08<00:00, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.94G/9.98G [01:08<00:00, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [01:09<00:00, 144MB/s]\n",
            "Downloading shards:  50% 1/2 [01:09<01:09, 69.45s/it]\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 31.5M/3.50G [00:00<00:13, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 62.9M/3.50G [00:00<00:13, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 94.4M/3.50G [00:00<00:13, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 126M/3.50G [00:00<00:14, 228MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 157M/3.50G [00:00<00:14, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 189M/3.50G [00:00<00:14, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 220M/3.50G [00:00<00:15, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 252M/3.50G [00:01<00:14, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 283M/3.50G [00:01<00:14, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 315M/3.50G [00:02<00:54, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 346M/3.50G [00:02<00:41, 75.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 377M/3.50G [00:02<00:32, 96.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 398M/3.50G [00:03<00:30, 103MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 419M/3.50G [00:03<00:27, 110MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 440M/3.50G [00:03<00:24, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 461M/3.50G [00:03<00:21, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 482M/3.50G [00:03<00:20, 146MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 503M/3.50G [00:03<00:19, 155MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 524M/3.50G [00:03<00:17, 165MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 556M/3.50G [00:03<00:16, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 587M/3.50G [00:04<00:14, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 619M/3.50G [00:04<00:13, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 650M/3.50G [00:04<00:13, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 682M/3.50G [00:04<00:12, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 713M/3.50G [00:04<00:12, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 744M/3.50G [00:04<00:12, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 776M/3.50G [00:04<00:12, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 807M/3.50G [00:05<00:12, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 839M/3.50G [00:05<00:13, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 860M/3.50G [00:07<01:17, 34.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 891M/3.50G [00:07<00:54, 47.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 912M/3.50G [00:07<00:45, 57.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 933M/3.50G [00:08<00:38, 67.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 954M/3.50G [00:08<00:31, 81.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 975M/3.50G [00:08<00:26, 95.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.01G/3.50G [00:08<00:20, 122MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.03G/3.50G [00:08<00:18, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.05G/3.50G [00:08<00:16, 145MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.07G/3.50G [00:08<00:15, 154MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.09G/3.50G [00:08<00:14, 162MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.12G/3.50G [00:08<00:13, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.15G/3.50G [00:09<00:11, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.18G/3.50G [00:09<00:11, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.22G/3.50G [00:09<00:15, 144MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.25G/3.50G [00:09<00:13, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.27G/3.50G [00:09<00:13, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.29G/3.50G [00:09<00:12, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:10<00:11, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.35G/3.50G [00:10<00:10, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.37G/3.50G [00:10<00:24, 85.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.41G/3.50G [00:11<00:18, 110MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.44G/3.50G [00:11<00:16, 127MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.46G/3.50G [00:11<00:15, 131MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [00:11<00:14, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.50G/3.50G [00:11<00:13, 149MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.52G/3.50G [00:11<00:12, 161MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.54G/3.50G [00:11<00:11, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.56G/3.50G [00:11<00:11, 163MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.58G/3.50G [00:12<00:13, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.60G/3.50G [00:12<00:23, 82.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.64G/3.50G [00:12<00:16, 111MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.66G/3.50G [00:12<00:14, 123MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.68G/3.50G [00:13<00:14, 128MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.70G/3.50G [00:13<00:13, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.72G/3.50G [00:13<00:12, 146MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.75G/3.50G [00:13<00:10, 166MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.78G/3.50G [00:13<00:09, 178MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.80G/3.50G [00:13<00:09, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.84G/3.50G [00:13<00:08, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.87G/3.50G [00:13<00:08, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.90G/3.50G [00:14<00:07, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.93G/3.50G [00:14<00:07, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.96G/3.50G [00:14<00:07, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 1.99G/3.50G [00:14<00:06, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.02G/3.50G [00:14<00:06, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.06G/3.50G [00:14<00:06, 220MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.09G/3.50G [00:14<00:06, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.12G/3.50G [00:15<00:06, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.15G/3.50G [00:15<00:05, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.18G/3.50G [00:15<00:05, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.21G/3.50G [00:15<00:05, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.24G/3.50G [00:15<00:05, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.28G/3.50G [00:15<00:05, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.31G/3.50G [00:15<00:04, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.34G/3.50G [00:16<00:05, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.37G/3.50G [00:16<00:05, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.40G/3.50G [00:16<00:04, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.43G/3.50G [00:16<00:04, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.46G/3.50G [00:16<00:04, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.50G/3.50G [00:16<00:04, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.52G/3.50G [00:16<00:05, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.54G/3.50G [00:17<00:05, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.56G/3.50G [00:17<00:04, 194MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.58G/3.50G [00:17<00:04, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.60G/3.50G [00:17<00:04, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.63G/3.50G [00:17<00:04, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.66G/3.50G [00:17<00:04, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.68G/3.50G [00:17<00:04, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.71G/3.50G [00:17<00:04, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.73G/3.50G [00:18<00:04, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.75G/3.50G [00:18<00:04, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.78G/3.50G [00:18<00:03, 191MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.80G/3.50G [00:18<00:03, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.82G/3.50G [00:18<00:03, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.85G/3.50G [00:18<00:03, 191MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.87G/3.50G [00:18<00:03, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.89G/3.50G [00:18<00:03, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.92G/3.50G [00:19<00:03, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.94G/3.50G [00:19<00:03, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.97G/3.50G [00:19<00:02, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.99G/3.50G [00:19<00:02, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.02G/3.50G [00:19<00:02, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.05G/3.50G [00:19<00:02, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.08G/3.50G [00:19<00:01, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.11G/3.50G [00:20<00:01, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.15G/3.50G [00:20<00:01, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.18G/3.50G [00:20<00:01, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.21G/3.50G [00:20<00:01, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.23G/3.50G [00:22<00:07, 37.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.26G/3.50G [00:22<00:04, 51.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.29G/3.50G [00:22<00:02, 69.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.31G/3.50G [00:22<00:02, 81.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.33G/3.50G [00:23<00:01, 91.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.36G/3.50G [00:23<00:01, 103MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.39G/3.50G [00:23<00:00, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.41G/3.50G [00:23<00:00, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.43G/3.50G [00:23<00:00, 144MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.45G/3.50G [00:23<00:00, 147MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.48G/3.50G [00:27<00:00, 23.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [00:27<00:00, 126MB/s] \n",
            "Downloading shards: 100% 2/2 [01:37<00:00, 48.66s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:59<00:00, 29.79s/it]\n",
            "generation_config.json: 100% 174/174 [00:00<00:00, 599kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 1.62k/1.62k [00:00<00:00, 7.08MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 17.3MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 44.4MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 1.72MB/s]\n",
            "The model `jizzu/llama-2-7b-chat-law-finetune` and tokenizer `meta-llama/Llama-2-7b-chat-hf` are different, please ensure that they are compatible.\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/embeddings/__init__.py:29: LangChainDeprecationWarning: Importing embeddings from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.embeddings import HuggingFaceEmbeddings`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "modules.json: 100% 349/349 [00:00<00:00, 1.88MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 679kB/s]\n",
            "README.md: 100% 10.6k/10.6k [00:00<00:00, 38.2MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 290kB/s]\n",
            "config.json: 100% 571/571 [00:00<00:00, 2.68MB/s]\n",
            "model.safetensors: 100% 438M/438M [00:01<00:00, 243MB/s]\n",
            "tokenizer_config.json: 100% 363/363 [00:00<00:00, 1.62MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 59.3MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 40.2MB/s]\n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 1.09MB/s]\n",
            "1_Pooling/config.json: 100% 190/190 [00:00<00:00, 934kB/s]\n",
            "/content/streamlit_llamaindex_final.py:57: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context=ServiceContext.from_defaults(\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100% 2/2 [00:57<00:00, 28.62s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "The model `jizzu/llama-2-7b-chat-law-finetune` and tokenizer `meta-llama/Llama-2-7b-chat-hf` are different, please ensure that they are compatible.\n",
            "/content/streamlit_llamaindex_final.py:57: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context=ServiceContext.from_defaults(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n",
            "2024-04-16 01:09:39.702233: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-16 01:09:39.702290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-16 01:09:39.822684: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-16 01:09:42.223465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n",
        "! streamlit run streamlit_llamaindex_final.py & npx localtunnel --port 8501 --browser.gatherUsageStats false"
      ],
      "metadata": {
        "id": "cTAT1jKLREro"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}